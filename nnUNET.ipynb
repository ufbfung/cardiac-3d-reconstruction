{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRsuMTv3OfY3ce2+Sm80dc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufbfung/cardiac-3d-reconstruction/blob/main/nnUNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "This notebook is intended to get familiar with setting up nnU-Net as a baseline model against other models we plan to test against for segmentation and 3d reconstruction. Notably, EchoNet-Peds and a transformer-based EchoNet-Peds.\n",
        "\n",
        "Setup instructions are clearly laid out in their [GitHub repository](https://github.com/MIC-DKFZ/nnUNet)."
      ],
      "metadata": {
        "id": "SgNr4aI0so83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUwGsnyysh6U"
      },
      "outputs": [],
      "source": [
        "# Install or import relevant libraries\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install nnU-Net - should occur after installation of PyTorch\n",
        "!pip install nnunetv2"
      ],
      "metadata": {
        "id": "NBlYf6OotXst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n",
        "To install nnU-Net, the following steps should occur per documentation on [GitHub](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md)"
      ],
      "metadata": {
        "id": "iMBBAe79w8oW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up paths\n",
        "nnU-Net relies on environment variables to know where raw data, preprocessed data and trained model weights are stored. This section follows the setup as specified in the [GitHub repository for setting up paths](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md)\n",
        "\n",
        "Three environment variables will need to be set:\n",
        "- nnUNet_raw\n",
        "- nnUNet_preprocessed\n",
        "- nnUNet_results"
      ],
      "metadata": {
        "id": "fAaWWKM-tvj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhfW9QNvuLRR",
        "outputId": "a25f2160-28b0-4ea6-daea-dd9d2fdc86ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant libraries\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "root_path = '/content/drive/MyDrive/Stanford/biomedin260/final_project/nnUNet'\n",
        "nnUNet_raw = os.path.join(root_path,'raw')\n",
        "nnUNet_preprocessed = os.path.join(root_path,'preprocessed')\n",
        "nnUNet_results = os.path.join(root_path,'results')"
      ],
      "metadata": {
        "id": "lMSa_M0-vb9L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optionally install hiddenlayer\n",
        "This allows nnU-net to generate plots of the network topologies it generates."
      ],
      "metadata": {
        "id": "PrDxfvwWwk3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install hiddenlayer\n",
        "!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMJpjhSNw0R3",
        "outputId": "633613b3-3752-41d9-84ab-9738a0c53874"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n",
            "  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-81u5i14w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-81u5i14w\n",
            "  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hiddenlayer\n",
            "  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-py3-none-any.whl size=20004 sha256=291afa4340045258c042526d3cbeaf80475f5f193a9edd5879e25a9ae574168e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p9uin8p8/wheels/55/0e/e3/fdf2f92789305c0e320e0ab01f27fd4b757b1bb01c07d532c4\n",
            "Successfully built hiddenlayer\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.2\n"
          ]
        }
      ]
    }
  ]
}